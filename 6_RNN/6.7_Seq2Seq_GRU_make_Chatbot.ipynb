{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 챗봇 만들기 튜토리얼\n",
    "\n",
    "reference : https://teddylee777.github.io/pytorch/pytorch-seq2seq-chatbot/\n",
    "\n",
    "Datasets : https://github.com/songys/Chatbot_data/blob/master/ChatbotData.csv\n",
    "\n",
    "seq2seq_GRU 모델을 Pytorch로 구현 - 한글 챗봇 데이터를 학습시켜 추론해보는 단계까지 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12시 땡!</td>\n",
       "      <td>하루가 또 가네요.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1지망 학교 떨어졌어</td>\n",
       "      <td>위로해 드립니다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3박4일 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3박4일 정도 놀러가고 싶다</td>\n",
       "      <td>여행은 언제나 좋죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL 심하네</td>\n",
       "      <td>눈살이 찌푸려지죠.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11818</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11819</th>\n",
       "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
       "      <td>훔쳐보는 거 티나나봐요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11820</th>\n",
       "      <td>흑기사 해주는 짝남.</td>\n",
       "      <td>설렜겠어요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11821</th>\n",
       "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
       "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11822</th>\n",
       "      <td>힘들어서 결혼할까봐</td>\n",
       "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11823 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Q                         A  label\n",
       "0                       12시 땡!                하루가 또 가네요.      0\n",
       "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
       "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
       "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
       "...                        ...                       ...    ...\n",
       "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
       "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
       "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
       "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
       "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
       "\n",
       "[11823 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../csv_datasets/ChatbotData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = df['Q']\n",
    "answer = df['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             12시 땡!\n",
      "1        1지망 학교 떨어졌어\n",
      "2       3박4일 놀러가고 싶다\n",
      "3    3박4일 정도 놀러가고 싶다\n",
      "4            PPL 심하네\n",
      "Name: Q, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(question[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     하루가 또 가네요.\n",
      "1      위로해 드립니다.\n",
      "2    여행은 언제나 좋죠.\n",
      "3    여행은 언제나 좋죠.\n",
      "4     눈살이 찌푸려지죠.\n",
      "Name: A, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(answer[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-1. 한글 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[^ ?,.!A-Za-z0-9가-힣+]', re.UNICODE)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "# 한글, 영어, 숫자, 공백, ?!.,을 제외한 나머지 문자 제거\n",
    "korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "\n",
    "# 패턴 컴파일\n",
    "normalizer = re.compile(korean_pattern)\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수정 전 : 가끔 궁금해\n",
      "수정 후 : 가끔 궁금해\n"
     ]
    }
   ],
   "source": [
    "print(\"수정 전 : {}\".format(question[11]))\n",
    "print(\"수정 후 : {}\".format(normalizer.sub(\"\", question[11])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수정 전 : 자랑하는 자리니까요.\n",
      "수정 후 : 자랑하는 자리니까요.\n"
     ]
    }
   ],
   "source": [
    "print(\"수정 전 : {}\".format(answer[10]))\n",
    "print(\"수정 후 : {}\".format(normalizer.sub(\"\", answer[10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'금수저로 태어났으면 좋았을텐데'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(sentence):\n",
    "    return normalizer.sub(\"\", sentence)\n",
    "\n",
    "normalize(question[345])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-2 한글 형태소 분석기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "# 형태소 분석기\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['자랑', '하는', '자리', '니까', '요', '.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okt.morphs(normalize(answer[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 전처리를 함수화\n",
    "def clean_text(sentence, tagger):\n",
    "    \n",
    "    # print(sentence)\n",
    "    \n",
    "    sentence = normalize(sentence)\n",
    "    # print(sentence)\n",
    "    \n",
    "    sentence = tagger.morphs(sentence)\n",
    "    # print(sentence)\n",
    "    \n",
    "    sentence = ' '.join(sentence)\n",
    "    # print(sentence)\n",
    "    \n",
    "    sentence = sentence.lower()\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sns 보면 나 만 빼고 다 행복 해보여'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(question[10], okt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11823, 11823)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question), len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [clean_text(sent, okt) for sent in question.values[:1000]]\n",
    "answers = [clean_text(sent, okt) for sent in answer.values[:1000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡 !', '1 지망 학교 떨어졌어', '3 박 4일 놀러 가고 싶다', '3 박 4일 정도 놀러 가고 싶다', 'ppl 심하네']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하루 가 또 가네요 .',\n",
       " '위로 해 드립니다 .',\n",
       " '여행 은 언제나 좋죠 .',\n",
       " '여행 은 언제나 좋죠 .',\n",
       " '눈살 이 찌푸려지죠 .']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-3. 단어 사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = 0  # 패딩에 사용되는 토큰. (길이가 다른 시퀀스를 동일한 길이로 만들 때 사용)\n",
    "SOS_TOKEN = 1  # 시작 토큰. 시퀀스의 시작을 나타낸다.\n",
    "EOS_TOKEN = 2  # 종료 토큰. 시퀀스의 종료를 나타낸다.\n",
    "\n",
    "# Vocabulary 클래스를 만든다\n",
    "class WordVocab():\n",
    "    def __init__(self):\n",
    "        self.word2index = {  # word2index : 단어를 해당 인덱스에 매핑한다.\n",
    "            '<PAD>': PAD_TOKEN,  \n",
    "            '<SOS>': SOS_TOKEN,\n",
    "            '<EOS>': EOS_TOKEN,\n",
    "        }\n",
    "        \n",
    "        self.word2count = {}  # word2count : 각 단어의 빈도수를 저장한다.\n",
    "        \n",
    "        self.index2word = {  # index2word : 인덱스를 해당 단어에 매핑한다.\n",
    "            PAD_TOKEN: '<PAD>',\n",
    "            SOS_TOKEN: '<SOS>',\n",
    "            EOS_TOKEN: '<EOS>'\n",
    "        }\n",
    "        \n",
    "        self.n_words = 3   # 현재 어휘의 크기(단어 수). 초기값은 PAD, SOS, EOS 포함이므로 3.\n",
    "        \n",
    "    def add_sentence(self, sentence):  # 문장을 받아서\n",
    "        for word in sentence.split(' '):  # 문장을 공백 기준으로 단어로 분리한 후,\n",
    "            self.add_word(word)   # 각 단어를 add_word 메소드에 전달한다\n",
    "            \n",
    "    def add_word(self, word):  # 단어를 사전에 추가하는 역할\n",
    "        if word not in self.word2index:  # 단어가 word2index에 없다면, 단어를 word2index와 index2word에 추가, \n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1  # 해당 단어의 빈도를 1로 설정\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count += 1 # 단어가 이미 word2index에 있다면, 해당 단어의 빈도수를 1 증가시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sns 보면 나 만 빼고 다 행복 해보여'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : sns 보면 나 만 빼고 다 행복 해보여\n",
      "==============================\n",
      "단어 사전\n",
      "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, 'sns': 3, '보면': 4, '나': 5, '만': 6, '빼고': 7, '다': 8, '행복': 9, '해보여': 10}\n",
      "{'sns': 1, '보면': 1, '나': 1, '만': 1, '빼고': 1, '다': 1, '행복': 1, '해보여': 1}\n",
      "{0: '<PAD>', 1: '<SOS>', 2: '<EOS>', 3: 'sns', 4: '보면', 5: '나', 6: '만', 7: '빼고', 8: '다', 9: '행복', 10: '해보여'}\n"
     ]
    }
   ],
   "source": [
    "print(\"원문 : {}\".format(questions[10]))\n",
    "\n",
    "lang = WordVocab()\n",
    "lang.add_sentence(questions[10])\n",
    "print(\"===\"*10)\n",
    "print(\"단어 사전\")\n",
    "print(lang.word2index)\n",
    "print(lang.word2count)\n",
    "print(lang.index2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1-4 padding to sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하나의 배치 구성을 위해서는 문장의 길이가 맞아야 한다.\n",
    "- 하지만, 문장 별로 길이가 다르기 때문에 길이를 맞춰 주는 작업을 수행해야 한다.\n",
    "- 짧은 문장은 남은 공간에 PAD 토큰을 추가하여 길이를 맞춰 주도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Sentence:[99, 47, 27, 62, 67, 8]\n",
      "output: [99, 47, 27, 62, 67, 8, 2, 0, 0, 0]\n",
      "Total Length : 10\n"
     ]
    }
   ],
   "source": [
    "max_length = 10  # 문장의 최대 길이\n",
    "sentence_length = 6  # 생성하려는 문장의 길이 정의. 임의로 6짜리 문장 생성한다.\n",
    "\n",
    "sentence_tokens = np.random.randint(low=3, high=100, size=(sentence_length,)) # 3부터 99 사이의 임의의 정수로 이뤄진 문장 생성. 길이는 6\n",
    "sentence_tokens = sentence_tokens.tolist() # 리스트로 변환\n",
    "print(\"Generated Sentence:{}\".format(sentence_tokens))\n",
    "\n",
    "sentence_tokens = sentence_tokens[:(max_length-1)]  # 문장의 길이가 max_length-1보다 길다면 길이를 줄인다는 뜻\n",
    "# max_length-1로 하는 이유는 <EOS>를 추가하기 위해서이다.\n",
    "\n",
    "token_length = len(sentence_tokens)\n",
    "\n",
    "\n",
    "# 문장의 맨 끝 부분에 <EOS> 토큰 추가\n",
    "sentence_tokens.append(2)  # <EOS> 토큰의 값은 2\n",
    "\n",
    "for i in range(token_length, max_length-1):  \n",
    "    \n",
    "    # 문장의 길이가 max_length 보다 짧다면, <PAD> 토큰(값 0)으로 문장을 채워서 max length에 맞춘다.\n",
    "    sentence_tokens.append(0) \n",
    "    \n",
    "print(\"output: {}\".format(sentence_tokens))\n",
    "print(\"Total Length : {}\".format(len(sentence_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1-5. 전처리 프로세스 클래스화\n",
    "\n",
    "- torch.utils.data.Dataset을 상속받아 TextDataset 클래스를 구현한다.\n",
    "- 데이터를 로드하고, 정규화 및 전처리, 토큰화를 진행한다.\n",
    "- 단어 사전을 생성하고 이에 따라 시퀀스로 변환한다.\n",
    "- 1-1 ~ 1-4 를 클래스화 한 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, csv_path, min_length=3, max_length=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        # TOKEN 정의\n",
    "        self.PAD_TOKEN = 0  # Padding 토큰\n",
    "        self.SOS_TOKEN = 1  # SOS 토큰\n",
    "        self.EOS_TOKEN = 2  # EOS 토큰\n",
    "        \n",
    "        self.tagger = Okt()  # 형태소 분석기\n",
    "        self.max_length = max_length  # 한 문장의 최대 길이 지정\n",
    "        \n",
    "        \n",
    "        # CSV 데이터 로드\n",
    "        df = pd.read_csv(\"../csv_datasets/ChatbotData.csv\")\n",
    "        \n",
    "        \n",
    "        # 한글 정규화\n",
    "        korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "        self.normalizer = re.complie(korean_pattern)\n",
    "        \n",
    "        \n",
    "        # src : 질문, tgt : 답변\n",
    "        src_clean = []\n",
    "        tgt_clean = []\n",
    "        \n",
    "        \n",
    "        # 단어 사전 생성\n",
    "        wordvocab = WordVocab()\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            src = row['Q']\n",
    "            tgt = row['A']\n",
    "            \n",
    "            # 한글 전처리\n",
    "            src = self.clean_text(src)\n",
    "            tgt = self.clean_text(tgt)\n",
    "            \n",
    "            if len(src.split()) > min_length and len(tgt.split()) > min_length:\n",
    "                # 최소 길이를 넘어가는 문장의 단어만 추가\n",
    "                wordvocab.add_sentence(src)\n",
    "                wordvocab.add_sentence(tgt)\n",
    "                src_clean.append(src)\n",
    "                tgt_clean.append(tgt)\n",
    "                \n",
    "                \n",
    "        self.srcs = src_clean\n",
    "        self.tgts = tgt_clean\n",
    "        self.wordvocab = wordvocab\n",
    "        \n",
    "    def normalize(self, sentence):\n",
    "        # 정규표현식에 따른 한글 정규화\n",
    "        return self.normalizer.sub(\"\", sentence)\n",
    "    \n",
    "    def clean_text(self, sentence):\n",
    "        # 한글 정규화\n",
    "        sentence = self.normalize(sentence)\n",
    "        \n",
    "        # 형태소 처리\n",
    "        sentence = self.tagger.morphs(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "        sentence = sentence.lower()\n",
    "        return sentence\n",
    "    \n",
    "    def texts_to_sequences(self, sentence):\n",
    "        # 문장 -> 시퀀스로 변환\n",
    "        return [self.wordvocab.word2index[w] for w in sentence.split()]\n",
    "    \n",
    "    def pad_sequence(self, sentence_tokens):\n",
    "        # 문장의 맨 끝 토큰은 제거\n",
    "        sentence_tokens = sentence_tokens[:(self.max_length-1)]\n",
    "        token_length = len(sentence_tokens)\n",
    "        \n",
    "        # 문장의 맨 끝 부분에 <EOS> 토큰 추가\n",
    "        sentence_tokens.append(self.EOS_TOKEN)\n",
    "        \n",
    "        for i in range(token_length, (self.max_length-1)):\n",
    "            # 나머지 빈 곳에 <PAD> 토큰 추가\n",
    "            sentence_tokens.append(self.PAD_TOKEN)\n",
    "            \n",
    "        return sentence_tokens\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.srcs[idx]\n",
    "        inputs_sequences = self.texts_to_sequences(inputs)\n",
    "        intputs_padded = self.pad_sequence(inputs_sequences)\n",
    "        \n",
    "        outputs = self.tgts[idx]\n",
    "        outputs_sequences = self.texts_to_sequences(outputs)\n",
    "        outputs_padded = self.pad_sequence(outputs_sequences)\n",
    "        \n",
    "        return torch.tensor(inputs_padded), torch.tensor(outputs_padded)\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.srcs)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.pyplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.pyplot'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1_8",
   "language": "python",
   "name": "torch1_8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
