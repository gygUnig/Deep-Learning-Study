{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM을 이용한 네이버 영화 리뷰 감정 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Download : https://github.com/e9t/nsmc/\n",
    "\n",
    "- ratings_train.txt\n",
    "- ratinns_test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. txt Dataset을 csv로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                               text  label\n",
      "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
      "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
      "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
      "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
      "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "columns = ['id', 'text', 'label']\n",
    "train_data = pd.read_csv('../txt_datasets/ratings_train.txt', sep='\\t', names=columns, skiprows=1).dropna() # null data 삭제\n",
    "test_data = pd.read_csv('../txt_datasets/ratings_test.txt', sep='\\t', names=columns, skiprows=1).dropna()\n",
    "\n",
    "# csv 파일로 변환\n",
    "train_data.to_csv('../csv_datasets/ratings_train.csv', index=False)\n",
    "test_data.to_csv('../csv_datasets/ratings_test.csv', index=False)\n",
    "\n",
    "\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x227483704f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data\n",
    "\n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Field를 지정한다. 한글 데이터를 다루므로 토크나이저 또한 별도로 지정해야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt  # 형태소 분석기중 하나인 Okt를 불러온다\n",
    "okt = Okt()  # Okt 클래스의 인스턴스 생성. 이 인스턴스를 사용하여 텍스트를 형태소로 분리할 수 있다.\n",
    "\n",
    "# torchtext에 내장된 데이터셋을 이용하는 게 아니므로, 각 컬럼별로 해당하는 Field를 지정해줘야 한다.\n",
    "TEXT = data.Field(tokenize=okt.morphs, include_lengths=True) # data.Field는 텍스트 데이터를 어떻게 처리할지 정의한다. torkenize 인자로 Okt.morphs를 사용하고 있으므로, 각 문장을 형태소로 분리한다.\n",
    "# include_lengths=True : 각 텍스트 데이터의 토큰화된 길이도 함께 반환하게 한다. 이 길이 정보를 패딩 작업에서 사용한다.\n",
    "LABEL = data.LabelField(dtype = torch.float) # data.LabelField는 label을 어떻게 처리할지 정의한다.\n",
    "\n",
    "# 위에서 정의한 TEXT와 LABEL은 이후 과정에서 데이터를 전처리하는데 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터를 불러오고 검증 데이터를 추가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSV 파일의 각 컬럼이 어떻게 처리될지를 정의하는 딕셔너리를 생성한다.\n",
    "# 'text' 컬럼은 TEXT Field를 사용하여 처리되고, 'label' 컬럼은 LABEL 필드를 사용하여 처리된다.\n",
    "fields = {'text' : ('text', TEXT), 'label' : ('label', LABEL)}\n",
    "\n",
    "# dictionary 형식은 {csv 컬럼명 : (데이터 컬럼명, Field 이름)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TabularDataset 은 데이터를 불러오면서 필드에서 정의했던 토큰화 방법으로 토큰화를 수행한다.\n",
    "train_data, test_data = data.TabularDataset.splits(\n",
    "    path = '../csv_datasets',\n",
    "    train = 'ratings_train.csv',\n",
    "    test = 'ratings_test.csv',\n",
    "    format = 'csv',\n",
    "    fields = fields, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'text': ['아', '더빙', '..', '진짜', '짜증나네요', '목소리'], 'label': '0'},\n",
       " {'text': ['흠',\n",
       "   '...',\n",
       "   '포스터',\n",
       "   '보고',\n",
       "   '초딩',\n",
       "   '영화',\n",
       "   '줄',\n",
       "   '....',\n",
       "   '오버',\n",
       "   '연기',\n",
       "   '조차',\n",
       "   '가볍지',\n",
       "   '않구나'],\n",
       "  'label': '1'},\n",
       " {'text': ['너', '무재', '밓었', '다그', '래서', '보는것을', '추천', '한', '다'], 'label': '0'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 불러온 데이터의 형태 확인\n",
    "vars(train_data[0]), vars(train_data[1]), vars(train_data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 수 : 149995\n",
      "테스트 데이터 수 : 49997\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터의 갯수 확인\n",
    "print(\"훈련 데이터 수 : {}\".format(len(train_data)))\n",
    "print(\"테스트 데이터 수 : {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터에 검증 데이터가 따로 주어져 있지 않으므로 생성해준다.\n",
    "import random\n",
    "random.seed(SEED)\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(SEED))\n",
    "# torchtext의 split 메서드는 기본적으로 데이터를 7:3 비율로 나눈다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 다음으로, 단어 벡터는 전처리된 단어 벡터를 받도록 한다. \n",
    "- 한글을 지원하는 fasttext.simple.300d 를 사용한다.\n",
    "- 사전훈련된 단어집에 없는 단어는 0으로 처리하는 것을 방지하기 위해 unk_init = torch.Tensor.normal_ 옵션을 준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 35000  # 단어장의 크기를 35000개로 제한한다. 만약 단어장에 더 많은 단어가 있으면, 빈도 수가 낮은 단어부터 제외된다.\n",
    "\n",
    "TEXT.build_vocab(  # 단어 집합 생성. 입력된 텍스트 데이터의 모든 고유 단어를 인덱스화하고 관련 정보 저장\n",
    "    train_data,  # 어휘를 구축할 훈련 데이터\n",
    "    max_size = MAX_VOCAB_SIZE,  # 빈도 수가 높은 단어 우선으로 포함시킨다\n",
    "    vectors = 'fasttext.simple.300d',  # 사용할 단어 벡터를 지정하는 것. fasttext.simple.300d는 FastText에서 제공하는 300차원의 사전 훈련된 임베딩이다.\n",
    "    unk_init = torch.Tensor.normal_ # 사전 훈련된 임베딩에 없는 단어를 초기화하는 방법을 지정\n",
    ")\n",
    "\n",
    "LABEL.build_vocab(train_data)  # label에 대한 어휘 사전 구축. 여기서는 label이 어떤 종류인지 정의하는데 사용된다(이진 분류, 다중 분류 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT 단어장의 갯수 : 35002\n",
      "LABEL 단어장의 갯수 : 2\n"
     ]
    }
   ],
   "source": [
    "# TEXT, LABEL 단어장의 갯수 확인\n",
    "\n",
    "print(\"TEXT 단어장의 갯수 : {}\".format(len(TEXT.vocab)))\n",
    "print(\"LABEL 단어장의 갯수 : {}\".format(len(LABEL.vocab)))\n",
    "\n",
    "# <unk>와 <pad> 토큰이 추가되어 있으므로 단어의 갯수가 35,002개이다. \n",
    "# <unk> : Unknown을 나타내며, 단어장에 없는 단어를 대체한다. train data에 등장하지 않은 단어가 test data에서 나타나면 해당 단어는 <unk>로 처리된다\n",
    "# <pad> : Padding을 나타내며, 배치 처리를 위해 모든 문장을 동일한 길이로 만들어야 할 때, 짧은 문장에 패딩을 추가하기 위해 사용된다. \n",
    "# 패딩은 실제 의미를 가지지 않는 토큰으로 문장의 길이를 맞춘다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', '.', '이', '영화', '의', '..', '가', '에', '을']\n",
      "defaultdict(None, {'0': 0, '1': 1})\n"
     ]
    }
   ],
   "source": [
    "# 단어와 인덱스 사이 매핑 확인\n",
    "\n",
    "# itos(integer to string) : 정수 인덱스를 단어로 매핑하는 리스트\n",
    "# 여기서 처음 10개의 요소를 출력하면, 단어장의 상위 10개 단어를 볼 수 있다.\n",
    "print(TEXT.vocab.itos[:10]) \n",
    "\n",
    "# 단어를 정수로 매핑\n",
    "# stoi(string to integer) : 단어를 정수 인덱스로 매핑하는 딕셔너리\n",
    "# LABEL의 경우 레이블(클래스)에 대한 매핑을 나타낸다.\n",
    "print(LABEL.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['야한', '장면', '기다리는것도', '곤욕', '이군'], 'label': '0'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 첫 번째 train 데이터 예시 출력\n",
    "vars(train_data.examples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터에서 길이가 0인 텍스트 찾기\n",
    "# 모든 훈련 데이터들 돌면서, 텍스트 길이가 0인 example의 인덱스를 출력한다\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    if len(train_data.examples[i].text)==0:print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BucketIterator를 이용하여 데이터 생성자를 만든다\n",
    "# 데이터를 배치로 나누고 반복할 수 있는 iterator를 생성하는 과정\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits( \n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size = BATCH_SIZE,\n",
    "    sort_key = lambda x: len(x.text),\n",
    "    sort_within_batch = True,\n",
    "    device = device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   60,   266,     0,  ...,    60,   480,   205],\n",
      "        [   25,   188,   553,  ...,   494, 22321,     4],\n",
      "        [  532,    67,  2539,  ...,   146,  5656,     5],\n",
      "        ...,\n",
      "        [    0,     7,  1479,  ...,   866,  1107,   286],\n",
      "        [ 5769,     0,  7947,  ...,    46,    25,    44],\n",
      "        [   62,     2,  1414,  ...,  5570,  1149,   199]], device='cuda:0'), tensor([16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16], device='cuda:0'))\n",
      "torch.Size([57, 64])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# train data의 첫 번째 배치에서 텍스트 부분을 가져온다\n",
    "print(next(iter(train_iterator)).text)\n",
    "\n",
    "\n",
    "# 패딩 제외 길이로 정렬된 (문장, 길이) 순의 데이터로 이루어져 있다.\n",
    "# 첫 번째 텐서는 배치의 텍스트 부분이다. 각 숫자는 특정 단어를 나타내며, 단어장 내에서의 인덱스이다.\n",
    "# 두 번째 텐서는 각 문장의 실제 길이를 나타낸다. 모든 문장의 실제 길이가 16으로 동일한 모습이다.\n",
    "\n",
    "text_tensor, text_lengths = next(iter(train_iterator)).text\n",
    "print(text_tensor.shape)  # 문장의 형태를 나타낸다. (이 배치에서 가장 긴 문장 길이, 배치 크기) \n",
    "# 실제 길이가 16인 문장들은 같은 배치에 모였고, 다른 배치들도 이와 유사한 방식으로 구성된다)\n",
    "print(text_lengths.shape) # 문장 길이의 형태를 나타낸다. (배치 크기)\n",
    "\n",
    "# BucketIterator는 배치 내의 문장을 가능한 같은 길이로 만들기 위해 패딩을 사용한다.\n",
    "# 따라서 배치 내의 모든 문장은 같은 길이인 57로 만들어진다.\n",
    "# 만약 실제 문장의 길이가 57보다 작다면, 패딩 토큰이 추가되어 문장의 길이가 57가 된다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  모델 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Multi-layer bi-directional LSTM을 써서 모델을 생성한다. \n",
    "- drop out 적용\n",
    "- nn.utils.rnn.packed_padded_sequence 써서 패킹/ 언패킹 처리를 할 것이다   \n",
    "\n",
    "- 패킹 : 다른 길이를 가진 여러 시퀀스를 하나의 패딩된 텐서로 묶는 과정. 시퀀스의 길이를 맞추기 위해 패딩 토큰을 추가할 수 있다\n",
    "\n",
    "- ex) [1,2,3] [4,5] ----> 패딩 후 : [1,2,3] [4,5,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 최종적인 hidden의 size는 [num layers * num directions, batch size, hidden dim] 이다.\n",
    "- 구체적으로 [forward_layer_0, backward_layer_0, forward_layer_1, bachward_layer_1, ..., forward_layer_n, backward_layer_n]의 형태로 출력된다.\n",
    "- 꼭대기층의 hidden만 필요로 하므로, hidden[-2,:,:]과 hidden[-1,:,:]만 뽑아서 concatenate할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nn.Embedding의 padding_idx 옵션 : 특정 인덱스에 해당하는 임베딩 벡터가 항상 0 벡터가 되도록 설정한다.\n",
    "- 패딩을 나타내는 토큰에 사용되며, 패딩이 모델에 정보를 추가하지 않도록 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(3,5,padding_idx=1)  # 3: 임베딩 레이어에 입력될 가능한 토큰의 갯수, 5: 각 토큰을 5차원의 벡터로 변환\n",
    "test = torch.tensor([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4467,  0.6607,  0.0908,  0.4816,  1.4613],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.4984,  0.1401, -0.1989,  0.1570, -0.4236]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(emb(test)) # padding_idx에 해당하는 벡터는 0으로 나온다.(인덱스 1에 해당하는 패딩 벡터 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_shape(name, data):\n",
    "#     print(f'{name} has shape {data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)  # TEXT를 밀집 벡터로 변환한다.  padding_idx=pad_idx : 패딩 토큰에 해당하는 벡터가 0이 되도록 지정\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout) # embedding_dim 차원의 입력을 받아 hidden_dim 차원의 hidden state를 출력한다.\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # 최종 출력을 생성하는 FC Layer. 양 방향 LSTM이므로 hidden_dim * 2를 입력 차원으로 사용한다\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, text, text_lengths):\n",
    "        # text = [sent_len, batch_size]\n",
    "        # print_shape('text',text)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(text))  # 텍스트가 임베딩 레이어를 통과하여 밀집 벡터로 변환되고,  dropout이 적용된다\n",
    "        # embedded = [sent_len, batch_size, emb_dim]\n",
    "        # print_shape('embedded', embedded)\n",
    "        \n",
    "        # pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths)  # 패딩된 시퀀스를 패킹한다. 이는 계산 효율성을 높이기 위해 사용되며, 길이가 다른 여러 시퀀스를 하나의 배치로 효과적으로 처리한다.\n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)  # 패킹된 임베딩이 LSTM 레이어를 통과하며, 이 과정에서 입력 시퀀스의 순서 정보가 학습된다.output, hidden state, cell state를 얻으며, hidden state와 cell state는 각각 시퀀스 내의 중간 정보를 저장한다. \n",
    "        # print_shape('packed_output', packed_output)\n",
    "        # print_shape('hidden', hidden)\n",
    "        # print_shape('cell', cell)\n",
    "        \n",
    "        # unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)  # 언패킹 과정에서 패킹된 출력은 다시 원래 형태로 변환된다.\n",
    "        # print_shape('output', output)\n",
    "        # print_shape('output_lengths', output_lengths)\n",
    "        \n",
    "        \n",
    "        # output = [sent_len. batch_size, hidden_dim * num_directions]\n",
    "        # output over padding tokens are zero tensors\n",
    "        # hidden = [num_layers * num_directions, batch_size, hidden_dim]\n",
    "        # cell = [num_layers * num_directions, batch_size, hidden_dim]\n",
    "        \n",
    "        # concat the final forward and backward hidden layers\n",
    "        # and apply drop-out\n",
    "        \n",
    "        # print_shape('hidden[-2, :, :]', hidden[-2, :, :])\n",
    "        # print_shape('hidden[-1, :, :]', hidden[-1, :, :])\n",
    "        \n",
    "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        # 마지막 hidden state는 정방향 및 역방향 LSTM의 출력을 연결하여 생성된다. 연결된 hidden state에 drop-out을 적용한다\n",
    "        # print_shape('hidden', hidden)\n",
    "        # hidden = [batch_size, hidden_dim * num_directions]\n",
    "        \n",
    "        res = self.fc(hidden)  # 최종 hidden state가 FC layer를 통과하여 최종 출력을 생성한다.\n",
    "        # print_shape('res',res)\n",
    "        \n",
    "        return res \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter 설정\n",
    "\n",
    "INPUT_DIM = len(TEXT.vocab)  # 단어장에 있는 고유한 단어의 수\n",
    "EMBEDDING_DIM = 300   # fasttxt dim과 동일하게 설정\n",
    "HIDDEN_DIM = 256  # hidden state의 크기\n",
    "OUTPUT_DIM = 1  # 모델의 최종 출력 크기\n",
    "N_LAYERS = 2  # 층의 수\n",
    "BIDIRECTIONAL = True  # 양방향 여부\n",
    "DROPOUT = 0.5  # Drop 확률\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]  # 패딩 인덱스로, 패딩 토큰에 해당하는 인덱스이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 모델은 13,220,857 개의 파라미터를 가지고 있다\n"
     ]
    }
   ],
   "source": [
    "# 모델의 파라미터 갯수 세보기\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"이 모델은 {:,} 개의 파라미터를 가지고 있다\".format(count_parameters(model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사전 학습된 fasttext모델의 단어 벡터를 embedding 레이어에 복사하여 담는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([35002, 300])\n"
     ]
    }
   ],
   "source": [
    "pretrained_embeddings = TEXT.vocab.vectors\n",
    "\n",
    "print(pretrained_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35002, 300])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1117, -0.4966,  0.1631,  ..., -1.4447,  0.8402, -0.8668],\n",
       "        [ 0.1032, -1.6268,  0.5729,  ...,  0.3180, -0.1626, -0.0417],\n",
       "        [ 0.0569, -0.0520,  0.2733,  ..., -0.0695, -0.1606, -0.0989],\n",
       "        ...,\n",
       "        [-0.2952,  0.8295, -0.9815,  ..., -0.2008, -0.9005, -0.7168],\n",
       "        [ 1.0138, -0.5817, -0.3477,  ..., -0.4448,  0.4386, -1.0933],\n",
       "        [ 0.5348, -0.9496, -1.9084,  ...,  0.4537,  1.2611,  2.0677]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding.weight.data.copy_(pretrained_embeddings)  # copy_ 메서드는 인수를 현재 모델의 웨이트에 복사한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기서 <unk>와 <pad>는 수동으로 0벡터로 만든다\n",
    "\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "UNK_IDX, PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0569, -0.0520,  0.2733,  ..., -0.0695, -0.1606, -0.0989],\n",
      "        ...,\n",
      "        [-0.2952,  0.8295, -0.9815,  ..., -0.2008, -0.9005, -0.7168],\n",
      "        [ 1.0138, -0.5817, -0.3477,  ..., -0.4448,  0.4386, -1.0933],\n",
      "        [ 0.5348, -0.9496, -1.9084,  ...,  0.4537,  1.2611,  2.0677]])\n"
     ]
    }
   ],
   "source": [
    "model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "\n",
    "print(model.embedding.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pad는 pad_idx 옵션 때문에 훈련 내내 0으로 남아있겠지만, unk는 학습될 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# loss function : binary cross entropy with logits : 임의의 실수를 입력으로 받아서 sigmoid 함수를 취해 0과 1 사이의 값으로 변환한 뒤, label과의 binary cross entropy를 계산한다\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 손실함수를 GPU에 올린다\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가를 위해 임의의 실수를 0과 1 두 정수 중 하나로 변환하는 함수를 만든다\n",
    "\n",
    "def binary_accuracy(preds, y):\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train function 만든다. 현재 batch.text는 (토큰들, 문장 길이)로 구성되어 있으니 분리한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, critertion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, text_lengths = batch.text\n",
    "        text_lengths = text_lengths.cpu()\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        # print_shape('predictions', predictions)\n",
    "        \n",
    "        loss = critertion(predictions, batch.label)\n",
    "        # print_shape('loss', loss)\n",
    "        \n",
    "        acc = binary_accuracy(predictions, batch.label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 평가를 위한 함수는 그래디언트 업데이트를 하지 않아야 하므로 with torch.no_grad(): 구문으로 감싼다.\n",
    "- dropout을 평가때는 적용하지 않아야 하므로 model.eval()을 넣어준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, critertion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator :\n",
    "            text, text_lengths = batch.text\n",
    "            text_lengths = text_lengths.cpu()\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            \n",
    "            loss = criterion(predictions, batch.label)\n",
    "            acc = binary_accuracy(predictions, batch.label)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "            \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "에폭마다 걸린 훈련시간을 측정하는 함수를 만든다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/10 | Epoch time : 0m 36s\n",
      "train Loss : 0.21319543356206416 | Train Acc : 91.18286190710005 %\n",
      " Val  Loss : 0.36098812095058913 |  Val  Acc : 86.40739143910733 %\n",
      "Epoch : 2/10 | Epoch time : 0m 35s\n",
      "train Loss : 0.20477817703712684 | Train Acc : 91.59186895049105 %\n",
      " Val  Loss : 0.3757393475283276 |  Val  Acc : 86.53421774506569 %\n",
      "Epoch : 3/10 | Epoch time : 0m 35s\n",
      "train Loss : 0.1958646133614705 | Train Acc : 91.96458798875756 %\n",
      " Val  Loss : 0.38614889237479394 |  Val  Acc : 86.47017045454545 %\n",
      "Epoch : 4/10 | Epoch time : 0m 35s\n",
      "train Loss : 0.18982169231187637 | Train Acc : 92.31741739656051 %\n",
      " Val  Loss : 0.40746685677335004 |  Val  Acc : 86.41658635302024 %\n",
      "Epoch : 5/10 | Epoch time : 0m 35s\n",
      "train Loss : 0.18129242627355363 | Train Acc : 92.66453382084096 %\n",
      " Val  Loss : 0.4211816519223662 |  Val  Acc : 86.45875609733842 %\n",
      "Epoch : 6/10 | Epoch time : 0m 35s\n",
      "train Loss : 0.17565286343736775 | Train Acc : 92.88850379091875 %\n",
      " Val  Loss : 0.41308987893121824 |  Val  Acc : 86.51868152347478 %\n",
      "Epoch : 7/10 | Epoch time : 0m 35s\n",
      "train Loss : 0.17322261876890313 | Train Acc : 92.92108893830337 %\n",
      " Val  Loss : 0.40768909522078256 |  Val  Acc : 86.30593039772727 %\n",
      "Epoch : 8/10 | Epoch time : 0m 35s\n",
      "train Loss : 0.16633151042559466 | Train Acc : 93.26746479030938 %\n",
      " Val  Loss : 0.41060938653324475 |  Val  Acc : 86.21207893910733 %\n",
      "Epoch : 9/10 | Epoch time : 0m 35s\n",
      "train Loss : 0.16222844710477075 | Train Acc : 93.40171981773167 %\n",
      " Val  Loss : 0.43392644048964774 |  Val  Acc : 86.39026988636364 %\n",
      "Epoch : 10/10 | Epoch time : 0m 35s\n",
      "train Loss : 0.15707027263619291 | Train Acc : 93.70397877431657 %\n",
      " Val  Loss : 0.47627212236296723 |  Val  Acc : 86.31893010302024 %\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 10\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'checkpoint/2.2_LSTM_Sentiment_Analysis.pt')\n",
    "        \n",
    "    print(\"Epoch : {}/{} | Epoch time : {}m {}s\".format(epoch+1, N_EPOCHS, epoch_mins, epoch_secs))\n",
    "    print(\"train Loss : {} | Train Acc : {} %\".format(train_loss, train_acc * 100))\n",
    "    print(\" Val  Loss : {} |  Val  Acc : {} %\".format(valid_loss, valid_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 데이터 Loss, Accuracy 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Loss : 0.366023244417232 |  Test Acc : 85.96562685259163 %\n"
     ]
    }
   ],
   "source": [
    "# save한 모델 불러오기\n",
    "model.load_state_dict(torch.load('checkpoint/2.2_LSTM_Sentiment_Analysis.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "print(\" Test Loss : {} |  Test Acc : {} %\".format(test_loss, test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 사용자 데이터 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict_semtiment 함수를 만든다.\n",
    "\n",
    "이 함수의 기능 :\n",
    "- sets the model to evaluation mode\n",
    "- tokenizes the sentence, i.e. splits it from a raw string into a list of tokens\n",
    "- indexes the tokens by converting them into their integer representation from our vocabulary\n",
    "- gets the length of our sequence\n",
    "- converts the indexes, which are a Python list into a PyTorch tensor\n",
    "- add a batch dimension by unsqueezeing\n",
    "- converts the length into a tensor\n",
    "- squashes the output prediction from a real number between 0 and 1 with the sigmoid function\n",
    "- converts the tensor holding a single value into an integer with the item() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = [tok for tok in okt.morphs(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(device)\n",
    "    tensor = tensor.unsqueeze(1)  # 배치\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.sigmoid(model(tensor, length_tensor))\n",
    "    \n",
    "    return prediction.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9852145314216614"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"영화 매우 재밌네\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010542043019086123"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"개노잼 ㅋㅋ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10448114573955536"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"김승희가 영화 더 잘 만들듯ㅋ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9945418238639832"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"결말이 참 인상깊은 영화였습니다. 따봉드립니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5397792458534241"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_sentiment(model, \"개지린다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch1_8",
   "language": "python",
   "name": "torch1_8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
