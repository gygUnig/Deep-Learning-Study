{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference : https://www.kaggle.com/code/tsunotsuno/debertav3-baseline-content-and-wording-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import transformers\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric, disable_progress_bar\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "\n",
    "# logging setting\n",
    "warnings.simplefilter(\"ignore\")\n",
    "logging.disable(logging.ERROR)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = '3'\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "def seed_everything(seed:int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    model_name=\"microsoft/deberta-v3-base\"\n",
    "    learning_rate=1.5e-5\n",
    "    weight_decay=0.02\n",
    "    hidden_dropout_prob=0.0 # 0.005\n",
    "    attention_probs_dropout_prob=0.0 # 0.005\n",
    "    num_train_epochs=3\n",
    "    n_splits=4\n",
    "    batch_size=8\n",
    "    random_seed=42\n",
    "    save_steps=100\n",
    "    max_length=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7165, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0071d51dab6d</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would use chemicals and substances to cha...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0072b649a88c</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The Egyptian society is really different from ...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00746c7c79c3</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>Many times the factories would, according to t...</td>\n",
       "      <td>-0.878889</td>\n",
       "      <td>-0.966330</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00791789cc1f</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>1 element of an ideal tragedy is that it shoul...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0086ef22de8f</td>\n",
       "      <td>39c16e</td>\n",
       "      <td>The three elements of an ideal tragedy are:  H...</td>\n",
       "      <td>-0.970237</td>\n",
       "      <td>-0.417058</td>\n",
       "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
       "      <td>On Tragedy</td>\n",
       "      <td>Chapter 13 \\r\\nAs the sequel to what has alrea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id  ...                                        prompt_text\n",
       "0  000e8c3c7ddb  ...  Background \\r\\nThe Third Wave experiment took ...\n",
       "1  0020ae56ffbf  ...  With one member trimming beef in a cannery, an...\n",
       "2  004e978e639e  ...  Egyptian society was structured like a pyramid...\n",
       "3  005ab0199905  ...  Egyptian society was structured like a pyramid...\n",
       "4  0070c9e7af47  ...  Background \\r\\nThe Third Wave experiment took ...\n",
       "5  0071d51dab6d  ...  With one member trimming beef in a cannery, an...\n",
       "6  0072b649a88c  ...  Egyptian society was structured like a pyramid...\n",
       "7  00746c7c79c3  ...  With one member trimming beef in a cannery, an...\n",
       "8  00791789cc1f  ...  Chapter 13 \\r\\nAs the sequel to what has alrea...\n",
       "9  0086ef22de8f  ...  Chapter 13 \\r\\nAs the sequel to what has alrea...\n",
       "\n",
       "[10 rows x 8 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = \"./CommonLit_data/\"\n",
    "\n",
    "prompts_train = pd.read_csv(DATA_DIR + \"prompts_train.csv\")\n",
    "prompts_test = pd.read_csv(DATA_DIR + \"prompts_test.csv\")\n",
    "summaries_train = pd.read_csv(DATA_DIR + \"summaries_train.csv\")\n",
    "summaries_test = pd.read_csv(DATA_DIR + \"summaries_test.csv\")\n",
    "sample_submission = pd.read_csv(DATA_DIR + \"sample_submission.csv\")\n",
    "\n",
    "train = summaries_train.merge(prompts_train, how=\"left\", on=\"prompt_id\")\n",
    "test = summaries_test.merge(prompts_test, how=\"left\", on=\"prompt_id\")\n",
    "\n",
    "# train = train.head(100)\n",
    "print(train.shape)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>student_id</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>text</th>\n",
       "      <th>content</th>\n",
       "      <th>wording</th>\n",
       "      <th>prompt_question</th>\n",
       "      <th>prompt_title</th>\n",
       "      <th>prompt_text</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000e8c3c7ddb</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The third wave was an experimentto see how peo...</td>\n",
       "      <td>0.205683</td>\n",
       "      <td>0.380538</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0020ae56ffbf</td>\n",
       "      <td>ebad26</td>\n",
       "      <td>They would rub it up with soda to make the sme...</td>\n",
       "      <td>-0.548304</td>\n",
       "      <td>0.506755</td>\n",
       "      <td>Summarize the various ways the factory would u...</td>\n",
       "      <td>Excerpt from The Jungle</td>\n",
       "      <td>With one member trimming beef in a cannery, an...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004e978e639e</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>In Egypt, there were many occupations and soci...</td>\n",
       "      <td>3.128928</td>\n",
       "      <td>4.231226</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>005ab0199905</td>\n",
       "      <td>3b9047</td>\n",
       "      <td>The highest class was Pharaohs these people we...</td>\n",
       "      <td>-0.210614</td>\n",
       "      <td>-0.471415</td>\n",
       "      <td>In complete sentences, summarize the structure...</td>\n",
       "      <td>Egyptian Social Structure</td>\n",
       "      <td>Egyptian society was structured like a pyramid...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0070c9e7af47</td>\n",
       "      <td>814d6b</td>\n",
       "      <td>The Third Wave developed  rapidly because the ...</td>\n",
       "      <td>3.272894</td>\n",
       "      <td>3.219757</td>\n",
       "      <td>Summarize how the Third Wave developed over su...</td>\n",
       "      <td>The Third Wave</td>\n",
       "      <td>Background \\r\\nThe Third Wave experiment took ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     student_id  ... fold\n",
       "0  000e8c3c7ddb  ...  3.0\n",
       "1  0020ae56ffbf  ...  2.0\n",
       "2  004e978e639e  ...  1.0\n",
       "3  005ab0199905  ...  1.0\n",
       "4  0070c9e7af47  ...  3.0\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gkf = GroupKFold(n_splits=CFG.n_splits)\n",
    "\n",
    "for i, (_, val_index) in enumerate(gkf.split(train, groups=train[\"prompt_id\"])):\n",
    "    train.loc[val_index, \"fold\"] = i  # train 데이터프레임에 \"fold\" 열을 추가하고, i를 할당한다(fold 번호)\n",
    "    \n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    return {\"rmse\" : rmse}\n",
    "\n",
    "def compute_mcrmse(eval_pred):\n",
    "    \n",
    "    preds, labels = eval_pred\n",
    "    \n",
    "    col_rmse = np.srqt(np.mean((preds - labels) ** 2, axis=0))\n",
    "    mcrmse = np.mean(col_rmse)\n",
    "    \n",
    "    return {\n",
    "        \"content_rmse\": col_rmse[0],\n",
    "        \"wording_rmse\": col_rmse[1],\n",
    "        \"mcrmse\": mcrmse\n",
    "    }\n",
    "\n",
    "def compt_score(content_true, content_pred, wording_true, wording_pred):\n",
    "    content_score = mean_squared_error(content_true, content_pred) ** (1/2)\n",
    "    wording_score = mean_squared_error(wording_true, wording_pred) ** (1/2)\n",
    "    \n",
    "    return (content_score + wording_score) / 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentScoreRegressor:\n",
    "    def __init__(self, model_name: str,\n",
    "                 model_dir: str,\n",
    "                 target: str,\n",
    "                 hidden_dropout_prob: float,\n",
    "                 attention_probs_dropout_prob: float,\n",
    "                 max_length: int,):\n",
    "        self.text_cols = [\"text\"]\n",
    "        self.target = target\n",
    "        self.target_cols = [target]\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.model_dir = model_dir\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model_config = AutoConfig.from_pretrained(model_name)\n",
    "        \n",
    "        self.model_config.update({\n",
    "            \"hidden_dropout_prob\": hidden_dropout_prob,\n",
    "            \"attention_probs_dropout_prob\": attention_probs_dropout_prob,\n",
    "            \"num_labels\" : 1,\n",
    "            \"problem_type\": \"regression\"\n",
    "        })\n",
    "        \n",
    "        seed_everything(seed=42)\n",
    "        \n",
    "        self.data_collator = DataCollatorWithPadding(\n",
    "            tokenizer=self.tokenizer\n",
    "        )\n",
    "    \n",
    "    def tokenize_function(self, examples: pd.DataFrame):\n",
    "        labels = [examples[self.target]]\n",
    "        tokenized = self.tokenizer(examples[\"text\"],\n",
    "                                   padding=False,\n",
    "                                   truncation=True,\n",
    "                                   max_length=self.max_length)\n",
    "        return {\n",
    "            **tokenized,\n",
    "            \"labels\": labels\n",
    "        }\n",
    "        \n",
    "    def tokenize_function_test(self, examples: pd.DataFrame):\n",
    "        tokenized = self.tokenizer(examples[\"text\"],\n",
    "                                   padding=False,\n",
    "                                   truncation=True,\n",
    "                                   max_length=self.max_length)\n",
    "        return tokenized\n",
    "    \n",
    "    def train(self,\n",
    "              fold: int,\n",
    "              train_df: pd.DataFrame,\n",
    "              valid_df: pd.DataFrame,\n",
    "              batch_size: int,\n",
    "              learning_rate: float,\n",
    "              weight_decay: float,\n",
    "              save_steps: int,\n",
    "              num_train_epochs: int,\n",
    "              ) -> None:\n",
    "        \n",
    "        train_df = train_df[self.text_cols + self.target_cols]\n",
    "        valid_df = valid_df[self.text_cols + self.target_cols]\n",
    "        \n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(\n",
    "            self.model_name, config=self.model_config)\n",
    "        \n",
    "        train_dataset = Dataset.from_pandas(train_df, preserve_index=False)\n",
    "        val_dataset = Dataset.from_pandas(valid_df, preserve_index=False)\n",
    "        \n",
    "        train_tokenized_datasets = train_dataset.map(self.tokenize_function, batched=False)\n",
    "        val_tokenized_datasets = val_dataset.map(self.tokenize_function, batched=False)\n",
    "        \n",
    "        model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            load_best_model_at_end=True,\n",
    "            learning_rate=learning_rate,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=8,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            weight_decay=weight_decay,\n",
    "            report_to='none',  # 어디에 로그를 남길지 결정. 'none'은 로깅x\n",
    "            greater_is_better=False, # 메트릭 값이 클수록 좋은것인지 여부. 작을수록 좋으니 False\n",
    "            save_strategy=\"steps\", # 지정된 step마다 모델 저장\n",
    "            evaluation_strategy=\"steps\", #  # 지정된 step마다 evaluation 수행\n",
    "            eval_steps=save_steps,\n",
    "            save_steps=save_steps,\n",
    "            metric_for_best_model='rmse',\n",
    "            save_total_limit=1\n",
    "        )\n",
    "        \n",
    "        trainer = Trainer(\n",
    "            model=model_content,\n",
    "            args=training_args,\n",
    "            train_dataset=train_tokenized_datasets,\n",
    "            eval_dataset=val_tokenized_datasets,\n",
    "            tokenizer=self.tokenizer,\n",
    "            compute_metrics=compute_metrics,\n",
    "            data_collator=self.data_collator\n",
    "        )\n",
    "        \n",
    "        trainer.train()\n",
    "        \n",
    "        model_content.save_pretrained(self.model_dir)\n",
    "        self.tokenizer.save_pretrained(self.model_dir)\n",
    "        \n",
    "    def predict(self,\n",
    "                test_df: pd.DataFrame,\n",
    "                fold: int):\n",
    "        test_ = test_df[self.text_cols]\n",
    "        \n",
    "        test_dataset = Dataset.from_pandas(test_, preserve_index=False)\n",
    "        test_tokenized_dataset = test_dataset.map(self.tokenize_function_test, batched=False)\n",
    "        \n",
    "        model_content = AutoModelForSequenceClassification.from_pretrained(\"{}\".format(\n",
    "            self.model_dir\n",
    "        ))\n",
    "        model_content.eval()\n",
    "        \n",
    "        model_fold_dir = os.path.join(self.model_dir, str(fold))\n",
    "        \n",
    "        test_args = TrainingArguments(\n",
    "            output_dir=model_fold_dir,\n",
    "            do_train=False,\n",
    "            do_predict=True,\n",
    "            per_device_eval_batch_size=4,\n",
    "            dataloader_drop_last=False,\n",
    "        )\n",
    "        \n",
    "        # init trainer\n",
    "        infer_content = Trainer(\n",
    "            model=model_content,\n",
    "            tokenizer=self.tokenizer,\n",
    "            data_collator=self.data_collator,\n",
    "            args=test_args\n",
    "        )\n",
    "        \n",
    "        preds = infer_content.predict(test_tokenized_dataset)[0]\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_by_fold(\n",
    "    train_df: pd.DataFrame,\n",
    "    model_name: str,\n",
    "    target: str,\n",
    "    save_each_model: bool,\n",
    "    n_splits: int,\n",
    "    batch_size: int,\n",
    "    learning_rate: int,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    weight_decay: float,\n",
    "    num_train_epochs: int,\n",
    "    save_steps: int,\n",
    "    max_length: int):\n",
    "    \n",
    "    # delete old model files\n",
    "    safe_model_name = model_name.replace('/', '_')\n",
    "    if os.path.exists(model_name):\n",
    "        shutil.rmtree(model_name)\n",
    "        \n",
    "    os.mkdir(safe_model_name)\n",
    "    \n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(\"fold {} :\".format(fold))\n",
    "        \n",
    "        train_data = train_df[train_df[\"fold\"] != fold] \n",
    "        valid_data = train_df[train_df[\"fold\"] == fold]   \n",
    "        \n",
    "        if save_each_model == True:\n",
    "            model_dir = f\"{target}/{model_name}/fold_{fold}\"\n",
    "        else:\n",
    "            model_dir = f\"{model_name}/fold_{fold}\"\n",
    "            \n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir=model_dir,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length\n",
    "        )\n",
    "        \n",
    "        csr.train(\n",
    "            fold=fold,\n",
    "            train_df = train_data,\n",
    "            valid_df=valid_data,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate,\n",
    "            weight_decay=weight_decay,\n",
    "            num_train_epochs=num_train_epochs,\n",
    "            save_steps=save_steps,\n",
    "        )\n",
    "        \n",
    "def validate(\n",
    "    train_df: pd.DataFrame,\n",
    "    target: str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length: int) -> pd.DataFrame:\n",
    "    \n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold} :\")\n",
    "        \n",
    "        valid_data = train_df[train_df[\"fold\"] == fold]\n",
    "        \n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir=model_dir,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        \n",
    "        pred = csr.predict(\n",
    "            test_df=valid_data,\n",
    "            fold=fold\n",
    "        )\n",
    "        \n",
    "        train_df.loc[valid_data.index, f\"{target}_pred\"] = pred\n",
    "        \n",
    "    return train_df\n",
    "        \n",
    "        \n",
    "def predict(\n",
    "    test_df: pd.DataFrame,\n",
    "    target:str,\n",
    "    save_each_model: bool,\n",
    "    model_name: str,\n",
    "    hidden_dropout_prob: float,\n",
    "    attention_probs_dropout_prob: float,\n",
    "    max_length : int\n",
    "    ):\n",
    "    \"\"\"predict using mean folds\"\"\"\n",
    "\n",
    "    for fold in range(CFG.n_splits):\n",
    "        print(f\"fold {fold}:\")\n",
    "        \n",
    "        if save_each_model == True:\n",
    "            model_dir =  f\"{target}/{model_name}/fold_{fold}\"\n",
    "        else: \n",
    "            model_dir =  f\"{model_name}/fold_{fold}\"\n",
    "\n",
    "        csr = ContentScoreRegressor(\n",
    "            model_name=model_name,\n",
    "            target=target,\n",
    "            model_dir = model_dir, \n",
    "            hidden_dropout_prob=hidden_dropout_prob,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,\n",
    "            max_length=max_length,\n",
    "           )\n",
    "        \n",
    "        pred = csr.predict(\n",
    "            test_df=test_df, \n",
    "            fold=fold\n",
    "        )\n",
    "        \n",
    "        test_df[f\"{target}_pred_{fold}\"] = pred\n",
    "    \n",
    "    test_df[f\"{target}\"] = test_df[[f\"{target}_pred_{fold}\" for fold in range(CFG.n_splits)]].mean(axis=1)\n",
    "\n",
    "    return test_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0 :\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741cfc7c7e7642d7bca3dbd36dabece1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1917 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0c1049efe34fd9b6fe112a949eb68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43875548243522644, 'eval_rmse': 0.6623861789703369, 'eval_runtime': 144.995, 'eval_samples_per_second': 14.187, 'eval_steps_per_second': 1.779, 'epoch': 0.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55499386a5a4e81868970fe907b5484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/258 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.21685656905174255, 'eval_rmse': 0.4656786024570465, 'eval_runtime': 143.8209, 'eval_samples_per_second': 14.303, 'eval_steps_per_second': 1.794, 'epoch': 0.31}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\KSH\\Desktop\\Deep-Learning-Study\\Study\\Kaggle_CommonLit\\Debertav3-baseline-content-and-wording.ipynb 셀 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m target \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mwording\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train_by_fold(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         train,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         model_name\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mmodel_name,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         save_each_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         target\u001b[39m=\u001b[39;49mtarget,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         learning_rate\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mlearning_rate,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         hidden_dropout_prob\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mhidden_dropout_prob,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         attention_probs_dropout_prob\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mattention_probs_dropout_prob,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mweight_decay,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         num_train_epochs\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mnum_train_epochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         n_splits\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mn_splits,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         batch_size\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         save_steps\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49msave_steps,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         max_length\u001b[39m=\u001b[39;49mCFG\u001b[39m.\u001b[39;49mmax_length\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     train \u001b[39m=\u001b[39m validate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         target\u001b[39m=\u001b[39mtarget,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m         max_length\u001b[39m=\u001b[39mCFG\u001b[39m.\u001b[39mmax_length\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     rmse \u001b[39m=\u001b[39m mean_squared_error(train[target], train[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mtarget\u001b[39m}\u001b[39;00m\u001b[39m_pred\u001b[39m\u001b[39m\"\u001b[39m], squared\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\KSH\\Desktop\\Deep-Learning-Study\\Study\\Kaggle_CommonLit\\Debertav3-baseline-content-and-wording.ipynb 셀 10\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     model_dir \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m/fold_\u001b[39m\u001b[39m{\u001b[39;00mfold\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m csr \u001b[39m=\u001b[39m ContentScoreRegressor(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     model_name\u001b[39m=\u001b[39mmodel_name,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     target\u001b[39m=\u001b[39mtarget,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     max_length\u001b[39m=\u001b[39mmax_length\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m )\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m csr\u001b[39m.\u001b[39;49mtrain(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     fold\u001b[39m=\u001b[39;49mfold,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     train_df \u001b[39m=\u001b[39;49m train_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     valid_df\u001b[39m=\u001b[39;49mvalid_data,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     learning_rate\u001b[39m=\u001b[39;49mlearning_rate,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     num_train_epochs\u001b[39m=\u001b[39;49mnum_train_epochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     save_steps\u001b[39m=\u001b[39;49msave_steps,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m )\n",
      "\u001b[1;32mc:\\Users\\KSH\\Desktop\\Deep-Learning-Study\\Study\\Kaggle_CommonLit\\Debertav3-baseline-content-and-wording.ipynb 셀 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m training_args \u001b[39m=\u001b[39m TrainingArguments(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     output_dir\u001b[39m=\u001b[39mmodel_fold_dir,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     load_best_model_at_end\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m     save_total_limit\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=94'>95</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel_content,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=100'>101</a>\u001b[0m     data_collator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_collator\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m )\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m model_content\u001b[39m.\u001b[39msave_pretrained(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_dir)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/KSH/Desktop/Deep-Learning-Study/Study/Kaggle_CommonLit/Debertav3-baseline-content-and-wording.ipynb#X16sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39msave_pretrained(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_dir)\n",
      "File \u001b[1;32mc:\\Users\\KSH\\anaconda3\\envs\\torch201\\lib\\site-packages\\transformers\\trainer.py:1553\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[0;32m   1552\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[0;32m   1554\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m   1555\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[0;32m   1556\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[0;32m   1557\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[0;32m   1558\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\KSH\\anaconda3\\envs\\torch201\\lib\\site-packages\\transformers\\trainer.py:1837\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1834\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m   1835\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m-> 1837\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   1838\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1839\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1840\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1841\u001b[0m ):\n\u001b[0;32m   1842\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1843\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n\u001b[0;32m   1844\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for target in [\"content\", \"wording\"]:\n",
    "    train_by_fold(\n",
    "        train,\n",
    "        model_name=CFG.model_name,\n",
    "        save_each_model=False,\n",
    "        target=target,\n",
    "        learning_rate=CFG.learning_rate,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        weight_decay=CFG.weight_decay,\n",
    "        num_train_epochs=CFG.num_train_epochs,\n",
    "        n_splits=CFG.n_splits,\n",
    "        batch_size=CFG.batch_size,\n",
    "        save_steps=CFG.save_steps,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "    \n",
    "    \n",
    "    train = validate(\n",
    "        train,\n",
    "        target=target,\n",
    "        save_each_model=False,\n",
    "        model_name=CFG.model_name,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )\n",
    "\n",
    "    rmse = mean_squared_error(train[target], train[f\"{target}_pred\"], squared=False)\n",
    "    print(f\"cv {target} rmse: {rmse}\")\n",
    "\n",
    "    test = predict(\n",
    "        test,\n",
    "        target=target,\n",
    "        save_each_model=False,\n",
    "        model_name=CFG.model_name,\n",
    "        hidden_dropout_prob=CFG.hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob=CFG.attention_probs_dropout_prob,\n",
    "        max_length=CFG.max_length\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcrmse = compt_score(content_true=train[\"content\"], \n",
    "            content_pred=train[\"content_pred\"], \n",
    "            wording_true=train[\"wording\"],\n",
    "            wording_pred=train[\"wording_pred\"], \n",
    "           )\n",
    "print(f\"cv mcrmse: {mcrmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[\"student_id\", \"content\", \"wording\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7369"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "torch.cuda.init()\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch201_kernel",
   "language": "python",
   "name": "torch201"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
